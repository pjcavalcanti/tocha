{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "variables and parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "momentum = 0.1\n",
    "n_features = 3\n",
    "length = 10\n",
    "batch_size = 32\n",
    "eps = 1e-5\n",
    "affine=True\n",
    "track_running_stats=True\n",
    "device = torch.device(\"cpu\")\n",
    "dtype = torch.float64\n",
    "\n",
    "shape1 = (batch_size, n_features)\n",
    "shape2 = (batch_size, n_features, length)\n",
    "\n",
    "\n",
    "torch.manual_seed(0)\n",
    "x1 = torch.randn(shape1, dtype=dtype, requires_grad=True, device=device)\n",
    "x2 = torch.randn(shape2, dtype=dtype, requires_grad=True, device=device)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "rank 2 tensors:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "before normalization: running mean: tensor([0., 0., 0.], dtype=torch.float64)\n",
      "before normalization: running var: tensor([1., 1., 1.], dtype=torch.float64)\n",
      "after normalization: running mean: tensor([ 0.0005, -0.0229,  0.0165], dtype=torch.float64)\n",
      "after normalization: running var: tensor([1.0395, 0.9768, 1.0161], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "norm = torch.nn.BatchNorm1d(n_features, momentum=momentum, eps=eps, affine=affine, track_running_stats=track_running_stats, dtype=dtype)\n",
    "print(f\"before normalization: running mean: {norm.running_mean}\")\n",
    "print(f\"before normalization: running var: {norm.running_var}\")\n",
    "out1 = norm(x1)\n",
    "running_mean_torch, running_var_torch = norm.running_mean, norm.running_var\n",
    "print(f\"after normalization: running mean: {norm.running_mean}\")\n",
    "print(f\"after normalization: running var: {norm.running_var}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "normalization correct: True\n",
      "running mean correct: True\n",
      "running var correct: True\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([[1.03948093, 0.97679327, 1.01605829]]),\n",
       " array([1.03948093, 0.97679327, 1.01605829]))"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean = x1.mean(dim=0, keepdim=True)\n",
    "var = x1.var(dim=0, unbiased=False, keepdim=True)\n",
    "out1_man = (x1 - mean) / torch.sqrt(var + eps)\n",
    "print(f\"normalization correct: {torch.allclose(out1_man, out1)}\")\n",
    "\n",
    "n = torch.tensor(x1.shape[0])\n",
    "n = batch_size\n",
    "\n",
    "running_mean_man = torch.zeros(mean.shape, dtype=dtype)\n",
    "running_var_man = torch.ones(var.shape, dtype=dtype)\n",
    "\n",
    "running_mean_man = (1 - momentum) * running_mean_man + momentum * mean\n",
    "running_var_man = (1 - momentum) * running_var_man + momentum * var * n / (n - 1)\n",
    "\n",
    "print(f\"running mean correct: {torch.allclose(running_mean_man, running_mean_torch)}\") # type: ignore\n",
    "print(f\"running var correct: {torch.allclose(running_var_man, running_var_torch)}\") # type: ignore\n",
    "running_var_man.detach().numpy(), running_var_torch.detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "before normalization: running mean: tensor([0., 0., 0.], dtype=torch.float64)\n",
      "before normalization: running var: tensor([1., 1., 1.], dtype=torch.float64)\n",
      "after normalization: running mean: tensor([-0.0055,  0.0048,  0.0009], dtype=torch.float64)\n",
      "after normalization: running var: tensor([1.0006, 0.9999, 0.9947], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "norm2 = torch.nn.BatchNorm1d(n_features, momentum=momentum, eps=eps, affine=affine, track_running_stats=track_running_stats, dtype=dtype)\n",
    "print(f\"before normalization: running mean: {norm2.running_mean}\")\n",
    "print(f\"before normalization: running var: {norm2.running_var}\")\n",
    "out2 = norm2(x2)\n",
    "running_mean_torch2, running_var_torch2 = norm2.running_mean, norm2.running_var\n",
    "print(f\"after normalization: running mean: {norm2.running_mean}\")\n",
    "print(f\"after normalization: running var: {norm2.running_var}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean = x2.mean(dim=(0,2))\n",
    "var = x2.var(dim=(0,2), unbiased=False)\n",
    "out2_man = (x1 - mean) / torch.sqrt(var + eps)\n",
    "print(f\"normalization correct: {torch.allclose(out1_man, out1)}\")\n",
    "\n",
    "n = torch.tensor(x1.shape[0] * x1.shape[2])\n",
    "# n = batch_size\n",
    "\n",
    "running_mean_man = torch.zeros(mean.shape, dtype=dtype)\n",
    "running_var_man = torch.ones(var.shape, dtype=dtype)\n",
    "\n",
    "running_mean_man = (1 - momentum) * running_mean_man + momentum * mean\n",
    "running_var_man = (1 - momentum) * running_var_man + momentum * var * n / (n - 1)\n",
    "\n",
    "print(f\"running mean correct: {torch.allclose(running_mean_man, running_mean_torch)}\") # type: ignore\n",
    "print(f\"running mean correct: {torch.allclose(running_var_man, running_var_torch)}\") # type: ignore\n",
    "running_var_man.detach().numpy(), running_var_torch.detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 3, 10]) torch.Size([1, 3, 1]) torch.Size([1, 3, 1])\n",
      "normalization correct: True\n",
      "running mean correct: True\n",
      "running mean correct: True\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([-0.00548487,  0.00478185,  0.00094317]),\n",
       " array([-0.00548487,  0.00478185,  0.00094317]))"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean2 = x2.mean(dim=(0,2), keepdim=True)\n",
    "var2 = x2.var(dim=(0,2), unbiased=False, keepdim=True)\n",
    "print(x2.shape, mean2.shape, var2.shape)\n",
    "out2_man = (x2 - mean2) / torch.sqrt(var2 + eps)\n",
    "print(f\"normalization correct: {torch.allclose(out2_man, out2)}\")\n",
    "\n",
    "n2 = torch.tensor(x2.shape[0] * x2.shape[2])\n",
    "# n = batch_size\n",
    "\n",
    "running_mean_man2 = torch.zeros(mean2.shape, dtype=dtype)\n",
    "running_var_man2 = torch.ones(var2.shape, dtype=dtype)\n",
    "\n",
    "running_mean_man2 = (1 - momentum) * running_mean_man2 + momentum * mean2\n",
    "running_var_man2 = (1 - momentum) * running_var_man2 + momentum * var2 * n2 / (n2 - 1)\n",
    "\n",
    "print(f\"running mean correct: {torch.allclose(running_mean_man2.squeeze(), running_mean_torch2)}\") # type: ignore\n",
    "print(f\"running mean correct: {torch.allclose(running_var_man2.squeeze(), running_var_torch2)}\") # type: ignore\n",
    "# running_var_man2.squeeze().detach().numpy(), running_var_torch2.detach().numpy()\n",
    "running_mean_man2.squeeze().detach().numpy(), running_mean_torch2.detach().numpy()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
